{
  "generated_at": "2026-01-04T02:32:56.540087+00:00",
  "runs": [
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:14:48.914977+00:00",
      "repo_url": "https://github.com/sankeer28/Math-PDF-Generator-Web.git",
      "repo_name": "math-pdf-generator-web",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 17.34446120262146,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 23813,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "790288d9-3f5f-4fdb-9fb4-4a78bc402e00",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/math-pdf-generator-web-790288d9-3f5f-4fdb-9fb4-4a78bc402e00",
      "report_path": "google_gemini_2-5_flash/base/math-pdf-generator-web/h3__gemini-2-5-flash__base__math-pdf-generator-web__run1_20260103_221532_b5e0ac72.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:15:32.760611+00:00",
      "repo_url": "https://github.com/sankeer28/Math-PDF-Generator-Web.git",
      "repo_name": "math-pdf-generator-web",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 18.540796995162964,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 32786,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "3ac492e1-a8fb-4917-849a-c55da5ebef1f",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/math-pdf-generator-web-3ac492e1-a8fb-4917-849a-c55da5ebef1f",
      "report_path": "google_gemini_2-5_flash/best_practices/math-pdf-generator-web/h3__gemini-2-5-flash__best_practices__math-pdf-generator-web__run1_20260103_221601_2f78673a.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:16:01.780279+00:00",
      "repo_url": "https://github.com/sankeer28/Math-PDF-Generator-Web.git",
      "repo_name": "math-pdf-generator-web",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 62.80465912818909,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 13,
      "tokens_used": 55124,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "b05664e3-7e31-4447-be3e-103757ee3df2",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/math-pdf-generator-web-b05664e3-7e31-4447-be3e-103757ee3df2",
      "report_path": "openai_gpt5_mini/base/math-pdf-generator-web/h3__gpt-5-mini__base__math-pdf-generator-web__run1_20260103_221714_9290b7a2.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:17:14.747577+00:00",
      "repo_url": "https://github.com/sankeer28/Math-PDF-Generator-Web.git",
      "repo_name": "math-pdf-generator-web",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 76.71322512626648,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 14,
      "tokens_used": 72668,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "95a3f42d-e75c-40ff-9862-bb2a4cf50865",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/math-pdf-generator-web-95a3f42d-e75c-40ff-9862-bb2a4cf50865",
      "report_path": "openai_gpt5_mini/best_practices/math-pdf-generator-web/h3__gpt-5-mini__best_practices__math-pdf-generator-web__run1_20260103_221845_9d1c686c.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:18:45.539065+00:00",
      "repo_url": "https://github.com/sankeer28/Math-PDF-Generator-Web.git",
      "repo_name": "math-pdf-generator-web",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 118.96572589874268,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 25,
      "tokens_used": 314776,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "b39da598-2cb0-4dcb-a9b3-ccdf31caec4c",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/math-pdf-generator-web-b39da598-2cb0-4dcb-a9b3-ccdf31caec4c",
      "report_path": "deepseek_v3_2/base/math-pdf-generator-web/h3__deepseek-chat__base__math-pdf-generator-web__run1_20260103_222055_c71af014.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:20:56.156844+00:00",
      "repo_url": "https://github.com/sankeer28/Math-PDF-Generator-Web.git",
      "repo_name": "math-pdf-generator-web",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 117.19342303276062,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 20,
      "tokens_used": 200225,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "9383fb6e-cb2a-4a74-8185-4f0c3da3ad8b",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/math-pdf-generator-web-9383fb6e-cb2a-4a74-8185-4f0c3da3ad8b",
      "report_path": "deepseek_v3_2/best_practices/math-pdf-generator-web/h3__deepseek-chat__best_practices__math-pdf-generator-web__run1_20260103_222304_9d32e8e2.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:23:05.004479+00:00",
      "repo_url": "https://github.com/patrick204nqh/simple-webapp.git",
      "repo_name": "simple-webapp",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 21.877531051635742,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 12,
      "tokens_used": 60264,
      "error_count": 1,
      "warning_count": 1,
      "info_count": 1,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "738ea436-9e74-4da0-8859-4a9195f29895",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/simple-webapp-738ea436-9e74-4da0-8859-4a9195f29895",
      "report_path": "google_gemini_2-5_flash/base/simple-webapp/h3__gemini-2-5-flash__base__simple-webapp__run1_20260103_222343_8a41557e.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:23:43.554755+00:00",
      "repo_url": "https://github.com/patrick204nqh/simple-webapp.git",
      "repo_name": "simple-webapp",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 23.602842092514038,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 9,
      "tokens_used": 56791,
      "error_count": 1,
      "warning_count": 1,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "41943dde-48c6-43f4-bc2c-1a3ee2cb4a67",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/simple-webapp-41943dde-48c6-43f4-bc2c-1a3ee2cb4a67",
      "report_path": "google_gemini_2-5_flash/best_practices/simple-webapp/h3__gemini-2-5-flash__best_practices__simple-webapp__run1_20260103_222416_e94867b5.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:24:17.058961+00:00",
      "repo_url": "https://github.com/patrick204nqh/simple-webapp.git",
      "repo_name": "simple-webapp",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 139.94963097572327,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 32,
      "tokens_used": 319974,
      "error_count": 1,
      "warning_count": 1,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "1e4815a3-321f-4a2b-a11c-bd855ccb0a60",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/simple-webapp-1e4815a3-321f-4a2b-a11c-bd855ccb0a60",
      "report_path": "openai_gpt5_mini/base/simple-webapp/h3__gpt-5-mini__base__simple-webapp__run1_20260103_222649_1a4335fd.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:26:50.162054+00:00",
      "repo_url": "https://github.com/patrick204nqh/simple-webapp.git",
      "repo_name": "simple-webapp",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "failed",
      "generation_success": false,
      "generation_time": 51.40501022338867,
      "overall_score": 0,
      "dockerfile_score": null,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 0,
      "tokens_used": null,
      "error_count": null,
      "warning_count": null,
      "info_count": null,
      "has_errors": null,
      "is_clean": null,
      "dockerfile_syntax_valid": null,
      "k8s_syntax_valid": null,
      "run_id": null,
      "workspace_dir": null,
      "report_path": "openai_gpt5_mini/best_practices/simple-webapp/h3__gpt-5-mini__best_practices__simple-webapp__run1_20260103_222741_6f605823.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:27:41.974810+00:00",
      "repo_url": "https://github.com/patrick204nqh/simple-webapp.git",
      "repo_name": "simple-webapp",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 178.8507101535797,
      "overall_score": 66.3,
      "dockerfile_score": 98.0,
      "k8s_score": 79.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 35,
      "tokens_used": 356616,
      "error_count": 0,
      "warning_count": 7,
      "info_count": 1,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "eb4b10d2-9863-49c8-ac4a-ac2f6f003c50",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/simple-webapp-eb4b10d2-9863-49c8-ac4a-ac2f6f003c50",
      "report_path": "deepseek_v3_2/base/simple-webapp/h3__deepseek-chat__base__simple-webapp__run1_20260103_223121_9146a8e5.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:31:22.061400+00:00",
      "repo_url": "https://github.com/patrick204nqh/simple-webapp.git",
      "repo_name": "simple-webapp",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 151.03922080993652,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 29,
      "tokens_used": 263517,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 1,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "6fe07d3f-b057-48b5-bac0-abbf9ebe2304",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/simple-webapp-6fe07d3f-b057-48b5-bac0-abbf9ebe2304",
      "report_path": "deepseek_v3_2/best_practices/simple-webapp/h3__deepseek-chat__best_practices__simple-webapp__run1_20260103_223408_22aae975.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:34:09.134515+00:00",
      "repo_url": "https://github.com/IamLRBA/Banner-Designer-WebApp.git",
      "repo_name": "banner-designer-webapp",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 15.661738157272339,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 8,
      "tokens_used": 38313,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "aa53fe26-d3a5-4624-8fa9-31b96aef0597",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/banner-designer-webapp-aa53fe26-d3a5-4624-8fa9-31b96aef0597",
      "report_path": "google_gemini_2-5_flash/base/banner-designer-webapp/h3__gemini-2-5-flash__base__banner-designer-webapp__run1_20260103_223450_462f63b6.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:34:50.775617+00:00",
      "repo_url": "https://github.com/IamLRBA/Banner-Designer-WebApp.git",
      "repo_name": "banner-designer-webapp",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 20.45897102355957,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 8,
      "tokens_used": 28825,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "9c88055c-4c61-4c93-b270-ece2b6f05d43",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/banner-designer-webapp-9c88055c-4c61-4c93-b270-ece2b6f05d43",
      "report_path": "google_gemini_2-5_flash/best_practices/banner-designer-webapp/h3__gemini-2-5-flash__best_practices__banner-designer-webapp__run1_20260103_223535_299ffe37.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:35:36.304490+00:00",
      "repo_url": "https://github.com/IamLRBA/Banner-Designer-WebApp.git",
      "repo_name": "banner-designer-webapp",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 69.69720101356506,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 14,
      "tokens_used": 62888,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "979b3cbe-c29f-44c4-a23e-86f4e2c412f1",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/banner-designer-webapp-979b3cbe-c29f-44c4-a23e-86f4e2c412f1",
      "report_path": "openai_gpt5_mini/base/banner-designer-webapp/h3__gpt-5-mini__base__banner-designer-webapp__run1_20260103_223713_f7527920.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:37:14.311031+00:00",
      "repo_url": "https://github.com/IamLRBA/Banner-Designer-WebApp.git",
      "repo_name": "banner-designer-webapp",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 174.21412992477417,
      "overall_score": 73.66666666666666,
      "dockerfile_score": 100.0,
      "k8s_score": 96.66666666666666,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 28,
      "tokens_used": 191230,
      "error_count": 0,
      "warning_count": 1,
      "info_count": 1,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "433b50e8-f5b3-403c-85aa-f485ff973dff",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/banner-designer-webapp-433b50e8-f5b3-403c-85aa-f485ff973dff",
      "report_path": "openai_gpt5_mini/best_practices/banner-designer-webapp/h3__gpt-5-mini__best_practices__banner-designer-webapp__run1_20260103_224040_d2a7c10a.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:40:41.687220+00:00",
      "repo_url": "https://github.com/IamLRBA/Banner-Designer-WebApp.git",
      "repo_name": "banner-designer-webapp",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 138.14877104759216,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 26,
      "tokens_used": 274606,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "9c25fb0b-6e86-4756-8b63-de6318deeff2",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/banner-designer-webapp-9c25fb0b-6e86-4756-8b63-de6318deeff2",
      "report_path": "deepseek_v3_2/base/banner-designer-webapp/h3__deepseek-chat__base__banner-designer-webapp__run1_20260103_224315_fb6a417c.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:43:16.391737+00:00",
      "repo_url": "https://github.com/IamLRBA/Banner-Designer-WebApp.git",
      "repo_name": "banner-designer-webapp",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 147.9004988670349,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 24,
      "tokens_used": 288287,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 1,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "0f41691e-0be3-4a28-8d8a-1ccdbad6c842",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/banner-designer-webapp-0f41691e-0be3-4a28-8d8a-1ccdbad6c842",
      "report_path": "deepseek_v3_2/best_practices/banner-designer-webapp/h3__deepseek-chat__best_practices__banner-designer-webapp__run1_20260103_224555_293d9863.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:45:55.726397+00:00",
      "repo_url": "https://github.com/jan-bobrowski/lsfont.git",
      "repo_name": "lsfont",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 12.433842897415161,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 23427,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "14071da2-580c-4eed-a571-f5755eb6f11d",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/lsfont-14071da2-580c-4eed-a571-f5755eb6f11d",
      "report_path": "google_gemini_2-5_flash/base/lsfont/h3__gemini-2-5-flash__base__lsfont__run1_20260103_224619_c2a9467b.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:46:20.087680+00:00",
      "repo_url": "https://github.com/jan-bobrowski/lsfont.git",
      "repo_name": "lsfont",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 19.661602020263672,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 9,
      "tokens_used": 45504,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 2,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "7cac94fa-1251-4e6e-aeca-e4c8d4143006",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/lsfont-7cac94fa-1251-4e6e-aeca-e4c8d4143006",
      "report_path": "google_gemini_2-5_flash/best_practices/lsfont/h3__gemini-2-5-flash__best_practices__lsfont__run1_20260103_224653_20c5242d.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:46:53.290814+00:00",
      "repo_url": "https://github.com/jan-bobrowski/lsfont.git",
      "repo_name": "lsfont",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 43.464919090270996,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 10,
      "tokens_used": 37418,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "71da95c8-9631-40cf-b3f5-496db73a2244",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/lsfont-71da95c8-9631-40cf-b3f5-496db73a2244",
      "report_path": "openai_gpt5_mini/base/lsfont/h3__gpt-5-mini__base__lsfont__run1_20260103_224746_9d951cd9.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:47:46.819438+00:00",
      "repo_url": "https://github.com/jan-bobrowski/lsfont.git",
      "repo_name": "lsfont",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "failed",
      "generation_success": false,
      "generation_time": 52.339268922805786,
      "overall_score": 0,
      "dockerfile_score": null,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 0,
      "tokens_used": null,
      "error_count": null,
      "warning_count": null,
      "info_count": null,
      "has_errors": null,
      "is_clean": null,
      "dockerfile_syntax_valid": null,
      "k8s_syntax_valid": null,
      "run_id": null,
      "workspace_dir": null,
      "report_path": "openai_gpt5_mini/best_practices/lsfont/h3__gpt-5-mini__best_practices__lsfont__run1_20260103_224839_0201fed6.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:48:39.611171+00:00",
      "repo_url": "https://github.com/jan-bobrowski/lsfont.git",
      "repo_name": "lsfont",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 103.63211512565613,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 20,
      "tokens_used": 230333,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "385192e5-8fa0-4adf-990f-ca46db9ad365",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/lsfont-385192e5-8fa0-4adf-990f-ca46db9ad365",
      "report_path": "deepseek_v3_2/base/lsfont/h3__deepseek-chat__base__lsfont__run1_20260103_225033_44c68fec.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:50:33.567908+00:00",
      "repo_url": "https://github.com/jan-bobrowski/lsfont.git",
      "repo_name": "lsfont",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 142.72925114631653,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 25,
      "tokens_used": 314432,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "9f8ca7f3-e9a1-4efa-ac45-6586b8ae1903",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/lsfont-9f8ca7f3-e9a1-4efa-ac45-6586b8ae1903",
      "report_path": "deepseek_v3_2/best_practices/lsfont/h3__deepseek-chat__best_practices__lsfont__run1_20260103_225308_49b219ba.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:53:08.442028+00:00",
      "repo_url": "https://github.com/SoLiDinity/airwatch.git",
      "repo_name": "airwatch",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 42.018198013305664,
      "overall_score": 29.749999999999993,
      "dockerfile_score": 84.99999999999999,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 23,
      "tokens_used": 168864,
      "error_count": 1,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "2a365557-c025-4a0d-a324-ffdcb7cb9494",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/airwatch-2a365557-c025-4a0d-a324-ffdcb7cb9494",
      "report_path": "google_gemini_2-5_flash/base/airwatch/h3__gemini-2-5-flash__base__airwatch__run1_20260103_225400_0b2138ce.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:54:00.501980+00:00",
      "repo_url": "https://github.com/SoLiDinity/airwatch.git",
      "repo_name": "airwatch",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 37.982962131500244,
      "overall_score": 72.26666666666665,
      "dockerfile_score": 96.0,
      "k8s_score": 96.66666666666666,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 18,
      "tokens_used": 75516,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "0d83a9a3-035e-445a-aac5-bfa6625718ca",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/airwatch-0d83a9a3-035e-445a-aac5-bfa6625718ca",
      "report_path": "google_gemini_2-5_flash/best_practices/airwatch/h3__gemini-2-5-flash__best_practices__airwatch__run1_20260103_225524_0cfb930b.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T21:55:24.929747+00:00",
      "repo_url": "https://github.com/SoLiDinity/airwatch.git",
      "repo_name": "airwatch",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 314.4917800426483,
      "overall_score": 67.0,
      "dockerfile_score": 100.0,
      "k8s_score": 79.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 37,
      "tokens_used": 370502,
      "error_count": 0,
      "warning_count": 6,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "8a47152e-aeac-4f10-81bc-8adea6a47ebe",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/airwatch-8a47152e-aeac-4f10-81bc-8adea6a47ebe",
      "report_path": "openai_gpt5_mini/base/airwatch/h3__gpt-5-mini__base__airwatch__run1_20260103_230135_7f55e3d7.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:01:35.924918+00:00",
      "repo_url": "https://github.com/SoLiDinity/airwatch.git",
      "repo_name": "airwatch",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 281.15101194381714,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 53,
      "tokens_used": 617285,
      "error_count": 1,
      "warning_count": 1,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "bd0deffd-f42a-426c-a30e-809fe19da4ba",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/airwatch-bd0deffd-f42a-426c-a30e-809fe19da4ba",
      "report_path": "openai_gpt5_mini/best_practices/airwatch/h3__gpt-5-mini__best_practices__airwatch__run1_20260103_230706_a7eb0a15.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:07:07.425794+00:00",
      "repo_url": "https://github.com/SoLiDinity/airwatch.git",
      "repo_name": "airwatch",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 318.94393587112427,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 62,
      "tokens_used": 881675,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 4,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "d8cc405c-03c3-47db-8a11-7ee40e2646a5",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/airwatch-d8cc405c-03c3-47db-8a11-7ee40e2646a5",
      "report_path": "deepseek_v3_2/base/airwatch/h3__deepseek-chat__base__airwatch__run1_20260103_231306_ae45760b.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:13:07.461274+00:00",
      "repo_url": "https://github.com/SoLiDinity/airwatch.git",
      "repo_name": "airwatch",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 306.1708891391754,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 56,
      "tokens_used": 1023111,
      "error_count": 1,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "34066f38-b6bb-49a1-8af0-d7b46c94ab5b",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/airwatch-34066f38-b6bb-49a1-8af0-d7b46c94ab5b",
      "report_path": "deepseek_v3_2/best_practices/airwatch/h3__deepseek-chat__best_practices__airwatch__run1_20260103_231840_649dc6ef.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:18:41.215565+00:00",
      "repo_url": "https://github.com/cgize/DiceOpt_kcd2.git",
      "repo_name": "diceopt_kcd2",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 10.550549983978271,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 25873,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "e658cf25-87a1-41e0-98a1-97714e310c9f",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/diceopt_kcd2-e658cf25-87a1-41e0-98a1-97714e310c9f",
      "report_path": "google_gemini_2-5_flash/base/diceopt_kcd2/h3__gemini-2-5-flash__base__diceopt_kcd2__run1_20260103_231901_63b2e30d.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:19:01.805305+00:00",
      "repo_url": "https://github.com/cgize/DiceOpt_kcd2.git",
      "repo_name": "diceopt_kcd2",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 12.068280220031738,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 30785,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "153c9cc4-dafd-40ef-8e5b-bd05422435e4",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/diceopt_kcd2-153c9cc4-dafd-40ef-8e5b-bd05422435e4",
      "report_path": "google_gemini_2-5_flash/best_practices/diceopt_kcd2/h3__gemini-2-5-flash__best_practices__diceopt_kcd2__run1_20260103_231923_9451d135.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:19:23.551074+00:00",
      "repo_url": "https://github.com/cgize/DiceOpt_kcd2.git",
      "repo_name": "diceopt_kcd2",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 68.37084698677063,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 16,
      "tokens_used": 67561,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "01c6ba44-7ebf-49d6-bafe-ec961d1dafef",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/diceopt_kcd2-01c6ba44-7ebf-49d6-bafe-ec961d1dafef",
      "report_path": "openai_gpt5_mini/base/diceopt_kcd2/h3__gpt-5-mini__base__diceopt_kcd2__run1_20260103_232042_ae43f14b.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:20:42.351902+00:00",
      "repo_url": "https://github.com/cgize/DiceOpt_kcd2.git",
      "repo_name": "diceopt_kcd2",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 69.86681008338928,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 15,
      "tokens_used": 75848,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "23a29401-38d1-4712-9d89-3f1eab816bba",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/diceopt_kcd2-23a29401-38d1-4712-9d89-3f1eab816bba",
      "report_path": "openai_gpt5_mini/best_practices/diceopt_kcd2/h3__gpt-5-mini__best_practices__diceopt_kcd2__run1_20260103_232202_b16108a4.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:22:02.601137+00:00",
      "repo_url": "https://github.com/cgize/DiceOpt_kcd2.git",
      "repo_name": "diceopt_kcd2",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 108.50839924812317,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 21,
      "tokens_used": 207266,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "cc19f668-2bec-4638-ab84-6533fa7271cc",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/diceopt_kcd2-cc19f668-2bec-4638-ab84-6533fa7271cc",
      "report_path": "deepseek_v3_2/base/diceopt_kcd2/h3__deepseek-chat__base__diceopt_kcd2__run1_20260103_232401_19b805e2.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:24:01.727035+00:00",
      "repo_url": "https://github.com/cgize/DiceOpt_kcd2.git",
      "repo_name": "diceopt_kcd2",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 125.80359292030334,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 26,
      "tokens_used": 327304,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "02827b1e-1979-43a6-9e3c-60c0e5afb7b8",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/diceopt_kcd2-02827b1e-1979-43a6-9e3c-60c0e5afb7b8",
      "report_path": "deepseek_v3_2/best_practices/diceopt_kcd2/h3__deepseek-chat__best_practices__diceopt_kcd2__run1_20260103_232620_6ffda314.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:26:20.493877+00:00",
      "repo_url": "https://github.com/SchoolTimer/ParklandSchoolTimer.git",
      "repo_name": "parklandschooltimer",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 14.371918678283691,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 7,
      "tokens_used": 35503,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "d86836c8-ba7d-4814-b335-5d2e6cb76ec9",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/parklandschooltimer-d86836c8-ba7d-4814-b335-5d2e6cb76ec9",
      "report_path": "google_gemini_2-5_flash/base/parklandschooltimer/h3__gemini-2-5-flash__base__parklandschooltimer__run1_20260103_232644_e8c81d43.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:26:44.977259+00:00",
      "repo_url": "https://github.com/SchoolTimer/ParklandSchoolTimer.git",
      "repo_name": "parklandschooltimer",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 14.15051007270813,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 8,
      "tokens_used": 73937,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "c4b429a0-adf1-4359-932f-8490b02e31d6",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/parklandschooltimer-c4b429a0-adf1-4359-932f-8490b02e31d6",
      "report_path": "google_gemini_2-5_flash/best_practices/parklandschooltimer/h3__gemini-2-5-flash__best_practices__parklandschooltimer__run1_20260103_232708_59a533c9.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:27:08.740297+00:00",
      "repo_url": "https://github.com/SchoolTimer/ParklandSchoolTimer.git",
      "repo_name": "parklandschooltimer",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 48.16430068016052,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 13,
      "tokens_used": 63359,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "0b4a6680-d80a-42f8-8570-97739bc72437",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/parklandschooltimer-0b4a6680-d80a-42f8-8570-97739bc72437",
      "report_path": "openai_gpt5_mini/base/parklandschooltimer/h3__gpt-5-mini__base__parklandschooltimer__run1_20260103_232807_6b1bb55d.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:28:07.860502+00:00",
      "repo_url": "https://github.com/SchoolTimer/ParklandSchoolTimer.git",
      "repo_name": "parklandschooltimer",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 135.42844986915588,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 26,
      "tokens_used": 272067,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "3da9a121-0a2e-4603-8ed3-dd1b7c60e8dc",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/parklandschooltimer-3da9a121-0a2e-4603-8ed3-dd1b7c60e8dc",
      "report_path": "openai_gpt5_mini/best_practices/parklandschooltimer/h3__gpt-5-mini__best_practices__parklandschooltimer__run1_20260103_233035_516e63ba.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:30:35.767084+00:00",
      "repo_url": "https://github.com/SchoolTimer/ParklandSchoolTimer.git",
      "repo_name": "parklandschooltimer",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 103.40971422195435,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 22,
      "tokens_used": 345574,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "04308ff1-362b-4840-aab3-4c91732eab4c",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/parklandschooltimer-04308ff1-362b-4840-aab3-4c91732eab4c",
      "report_path": "deepseek_v3_2/base/parklandschooltimer/h3__deepseek-chat__base__parklandschooltimer__run1_20260103_233229_d84c52b4.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:32:29.754629+00:00",
      "repo_url": "https://github.com/SchoolTimer/ParklandSchoolTimer.git",
      "repo_name": "parklandschooltimer",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 139.96906065940857,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 27,
      "tokens_used": 527162,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "f0552073-e0f8-43b2-8318-9da345d28041",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/parklandschooltimer-f0552073-e0f8-43b2-8318-9da345d28041",
      "report_path": "deepseek_v3_2/best_practices/parklandschooltimer/h3__deepseek-chat__best_practices__parklandschooltimer__run1_20260103_233500_694f50fa.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:35:01.386872+00:00",
      "repo_url": "https://github.com/Mohit-Nathrani/Realtime-Chatting-WebApp.git",
      "repo_name": "realtime-chatting-webapp",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 53.3070387840271,
      "overall_score": 65.6,
      "dockerfile_score": 96.0,
      "k8s_score": 79.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 22,
      "tokens_used": 209620,
      "error_count": 0,
      "warning_count": 7,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "96034f42-68c6-4517-8df8-e5f2523dcfbe",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/realtime-chatting-webapp-96034f42-68c6-4517-8df8-e5f2523dcfbe",
      "report_path": "google_gemini_2-5_flash/base/realtime-chatting-webapp/h3__gemini-2-5-flash__base__realtime-chatting-webapp__run1_20260103_233738_72c9b848.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:37:38.961864+00:00",
      "repo_url": "https://github.com/Mohit-Nathrani/Realtime-Chatting-WebApp.git",
      "repo_name": "realtime-chatting-webapp",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 49.30466914176941,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 17,
      "tokens_used": 162040,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "ec9c5356-1581-4613-89c5-625c28b02c1c",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/realtime-chatting-webapp-ec9c5356-1581-4613-89c5-625c28b02c1c",
      "report_path": "google_gemini_2-5_flash/best_practices/realtime-chatting-webapp/h3__gemini-2-5-flash__best_practices__realtime-chatting-webapp__run1_20260103_233935_98a25d43.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:39:36.724075+00:00",
      "repo_url": "https://github.com/Mohit-Nathrani/Realtime-Chatting-WebApp.git",
      "repo_name": "realtime-chatting-webapp",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 84.2050609588623,
      "overall_score": 68.96666666666667,
      "dockerfile_score": 98.0,
      "k8s_score": 86.66666666666666,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 21,
      "tokens_used": 156535,
      "error_count": 0,
      "warning_count": 5,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "dfa3bb7a-faf3-4e23-add8-4b4729b7ca07",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/realtime-chatting-webapp-dfa3bb7a-faf3-4e23-add8-4b4729b7ca07",
      "report_path": "openai_gpt5_mini/base/realtime-chatting-webapp/h3__gpt-5-mini__base__realtime-chatting-webapp__run1_20260103_234213_15e2c4c0.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:42:14.514674+00:00",
      "repo_url": "https://github.com/Mohit-Nathrani/Realtime-Chatting-WebApp.git",
      "repo_name": "realtime-chatting-webapp",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 146.26305890083313,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 24,
      "tokens_used": 200937,
      "error_count": 1,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "92357c11-af66-45e5-8852-dd50e9e718f2",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/realtime-chatting-webapp-92357c11-af66-45e5-8852-dd50e9e718f2",
      "report_path": "openai_gpt5_mini/best_practices/realtime-chatting-webapp/h3__gpt-5-mini__best_practices__realtime-chatting-webapp__run1_20260103_234514_5939ab30.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:45:15.200494+00:00",
      "repo_url": "https://github.com/Mohit-Nathrani/Realtime-Chatting-WebApp.git",
      "repo_name": "realtime-chatting-webapp",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 222.10548520088196,
      "overall_score": 63.0,
      "dockerfile_score": 100.0,
      "k8s_score": 70.0,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 38,
      "tokens_used": 408754,
      "error_count": 2,
      "warning_count": 0,
      "info_count": 1,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": false,
      "run_id": "f06f8ec1-8deb-4070-881a-f3c65cb23a99",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/realtime-chatting-webapp-f06f8ec1-8deb-4070-881a-f3c65cb23a99",
      "report_path": "deepseek_v3_2/base/realtime-chatting-webapp/h3__deepseek-chat__base__realtime-chatting-webapp__run1_20260103_235043_80a9d55d.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:50:44.450704+00:00",
      "repo_url": "https://github.com/Mohit-Nathrani/Realtime-Chatting-WebApp.git",
      "repo_name": "realtime-chatting-webapp",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 170.22820591926575,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 32,
      "tokens_used": 425878,
      "error_count": 1,
      "warning_count": 1,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "a2e422dd-2b59-4ac1-9849-f7786ad9f830",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/realtime-chatting-webapp-a2e422dd-2b59-4ac1-9849-f7786ad9f830",
      "report_path": "deepseek_v3_2/best_practices/realtime-chatting-webapp/h3__deepseek-chat__best_practices__realtime-chatting-webapp__run1_20260103_235431_4d4cb56c.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:54:31.648029+00:00",
      "repo_url": "https://github.com/tschoffelen/csv-hero",
      "repo_name": "csv-hero",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 15.562263011932373,
      "overall_score": 70.93333333333332,
      "dockerfile_score": 96.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 30920,
      "error_count": 0,
      "warning_count": 3,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "8ecb44a2-6d62-4995-be50-b6a263b953db",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/csv-hero-8ecb44a2-6d62-4995-be50-b6a263b953db",
      "report_path": "google_gemini_2-5_flash/base/csv-hero/h3__gemini-2-5-flash__base__csv-hero__run1_20260103_235538_57514cb3.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:55:39.280487+00:00",
      "repo_url": "https://github.com/tschoffelen/csv-hero",
      "repo_name": "csv-hero",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 22.968602180480957,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 10,
      "tokens_used": 54319,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "cd11effb-7389-4abe-a377-acb3b97a7e57",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/csv-hero-cd11effb-7389-4abe-a377-acb3b97a7e57",
      "report_path": "google_gemini_2-5_flash/best_practices/csv-hero/h3__gemini-2-5-flash__best_practices__csv-hero__run1_20260103_235651_80c9a1c4.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:56:52.256153+00:00",
      "repo_url": "https://github.com/tschoffelen/csv-hero",
      "repo_name": "csv-hero",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 54.89213585853577,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 17,
      "tokens_used": 95610,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "3982be33-d510-44eb-805a-76af2c654c2c",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/csv-hero-3982be33-d510-44eb-805a-76af2c654c2c",
      "report_path": "openai_gpt5_mini/base/csv-hero/h3__gpt-5-mini__base__csv-hero__run1_20260103_235817_eea00357.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T22:58:17.795801+00:00",
      "repo_url": "https://github.com/tschoffelen/csv-hero",
      "repo_name": "csv-hero",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 156.4054319858551,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 36,
      "tokens_used": 336975,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 1,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "2c4f0260-1912-4e6a-94fb-633303ad2c75",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/csv-hero-2c4f0260-1912-4e6a-94fb-633303ad2c75",
      "report_path": "openai_gpt5_mini/best_practices/csv-hero/h3__gpt-5-mini__best_practices__csv-hero__run1_20260104_000244_46a97c10.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:02:45.297159+00:00",
      "repo_url": "https://github.com/tschoffelen/csv-hero",
      "repo_name": "csv-hero",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 131.81799125671387,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 27,
      "tokens_used": 375770,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "d09fef93-1d1a-4a74-a7d1-3a1914ce702c",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/csv-hero-d09fef93-1d1a-4a74-a7d1-3a1914ce702c",
      "report_path": "deepseek_v3_2/base/csv-hero/h3__deepseek-chat__base__csv-hero__run1_20260104_000525_42a45f53.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:05:25.841239+00:00",
      "repo_url": "https://github.com/tschoffelen/csv-hero",
      "repo_name": "csv-hero",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 173.22381281852722,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 31,
      "tokens_used": 303323,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 1,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "0787b68a-26ca-48b2-b21f-db53ec3dfee2",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/csv-hero-0787b68a-26ca-48b2-b21f-db53ec3dfee2",
      "report_path": "deepseek_v3_2/best_practices/csv-hero/h3__deepseek-chat__best_practices__csv-hero__run1_20260104_000830_d9ce3e53.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:08:30.528798+00:00",
      "repo_url": "https://github.com/isixe/MetaThief",
      "repo_name": "metathief",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 14.346439123153687,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 28224,
      "error_count": 1,
      "warning_count": 3,
      "info_count": 1,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "d131af28-4c78-4adc-ad79-4d426347f958",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/metathief-d131af28-4c78-4adc-ad79-4d426347f958",
      "report_path": "google_gemini_2-5_flash/base/metathief/h3__gemini-2-5-flash__base__metathief__run1_20260104_000909_e18f3916.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:09:09.800137+00:00",
      "repo_url": "https://github.com/isixe/MetaThief",
      "repo_name": "metathief",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 24.187299251556396,
      "overall_score": 73.6,
      "dockerfile_score": 96.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 9,
      "tokens_used": 310430,
      "error_count": 0,
      "warning_count": 1,
      "info_count": 1,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "c04ca9f4-f8ba-486c-8771-b8ef587cd8ff",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/metathief-c04ca9f4-f8ba-486c-8771-b8ef587cd8ff",
      "report_path": "google_gemini_2-5_flash/best_practices/metathief/h3__gemini-2-5-flash__best_practices__metathief__run1_20260104_001012_230105b2.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:10:12.684777+00:00",
      "repo_url": "https://github.com/isixe/MetaThief",
      "repo_name": "metathief",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 98.75812196731567,
      "overall_score": 71.63333333333333,
      "dockerfile_score": 98.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 31,
      "tokens_used": 259473,
      "error_count": 0,
      "warning_count": 3,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "cd6c8151-0352-4246-9522-88266a13a819",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/metathief-cd6c8151-0352-4246-9522-88266a13a819",
      "report_path": "openai_gpt5_mini/base/metathief/h3__gpt-5-mini__base__metathief__run1_20260104_001305_ea432d90.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:13:06.937622+00:00",
      "repo_url": "https://github.com/isixe/MetaThief",
      "repo_name": "metathief",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 109.11807894706726,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 24,
      "tokens_used": 197301,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "9959f40f-2e04-42d8-ac92-2b43454a0eb6",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/metathief-9959f40f-2e04-42d8-ac92-2b43454a0eb6",
      "report_path": "openai_gpt5_mini/best_practices/metathief/h3__gpt-5-mini__best_practices__metathief__run1_20260104_001510_50979a6a.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:15:10.752314+00:00",
      "repo_url": "https://github.com/isixe/MetaThief",
      "repo_name": "metathief",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 143.5800769329071,
      "overall_score": 71.63333333333333,
      "dockerfile_score": 98.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 25,
      "tokens_used": 369270,
      "error_count": 0,
      "warning_count": 3,
      "info_count": 1,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "7f155698-0c85-4fe5-81d7-c3a712033840",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/metathief-7f155698-0c85-4fe5-81d7-c3a712033840",
      "report_path": "deepseek_v3_2/base/metathief/h3__deepseek-chat__base__metathief__run1_20260104_001824_41e94edb.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:18:25.084838+00:00",
      "repo_url": "https://github.com/isixe/MetaThief",
      "repo_name": "metathief",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 204.24748587608337,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 34,
      "tokens_used": 500913,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "28e0bb43-b942-46c6-81b2-545952730699",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/metathief-28e0bb43-b942-46c6-81b2-545952730699",
      "report_path": "deepseek_v3_2/best_practices/metathief/h3__deepseek-chat__best_practices__metathief__run1_20260104_002226_530894d7.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:22:27.491978+00:00",
      "repo_url": "https://github.com/xixu-me/DeepLX-App",
      "repo_name": "deeplx-app",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 14.822096824645996,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 24194,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "931ca985-4f6b-44f2-ae5a-7c603021b52d",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/deeplx-app-931ca985-4f6b-44f2-ae5a-7c603021b52d",
      "report_path": "google_gemini_2-5_flash/base/deeplx-app/h3__gemini-2-5-flash__base__deeplx-app__run1_20260104_002252_6a6494f7.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:22:53.142238+00:00",
      "repo_url": "https://github.com/xixu-me/DeepLX-App",
      "repo_name": "deeplx-app",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 15.635408163070679,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 7,
      "tokens_used": 65634,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "2e659e3a-048b-4743-952a-075ceee5435f",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/deeplx-app-2e659e3a-048b-4743-952a-075ceee5435f",
      "report_path": "google_gemini_2-5_flash/best_practices/deeplx-app/h3__gemini-2-5-flash__best_practices__deeplx-app__run1_20260104_002318_b34b9bd8.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:23:19.046921+00:00",
      "repo_url": "https://github.com/xixu-me/DeepLX-App",
      "repo_name": "deeplx-app",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 45.91254687309265,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 9,
      "tokens_used": 33125,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "a8074d50-57fa-4d82-bef9-11b1da579aa1",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/deeplx-app-a8074d50-57fa-4d82-bef9-11b1da579aa1",
      "report_path": "openai_gpt5_mini/base/deeplx-app/h3__gpt-5-mini__base__deeplx-app__run1_20260104_002415_8fdf1f8a.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:24:15.622825+00:00",
      "repo_url": "https://github.com/xixu-me/DeepLX-App",
      "repo_name": "deeplx-app",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 88.32660222053528,
      "overall_score": 73.66666666666666,
      "dockerfile_score": 100.0,
      "k8s_score": 96.66666666666666,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 17,
      "tokens_used": 116745,
      "error_count": 0,
      "warning_count": 1,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "30ce8c6e-8116-49d7-b9b2-56cdd2b63050",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/deeplx-app-30ce8c6e-8116-49d7-b9b2-56cdd2b63050",
      "report_path": "openai_gpt5_mini/best_practices/deeplx-app/h3__gpt-5-mini__best_practices__deeplx-app__run1_20260104_002554_8307d5a0.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:25:55.327032+00:00",
      "repo_url": "https://github.com/xixu-me/DeepLX-App",
      "repo_name": "deeplx-app",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 94.61360907554626,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 17,
      "tokens_used": 226112,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 1,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "e90f5e32-60e2-43da-abdf-cb01369c3ad1",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/deeplx-app-e90f5e32-60e2-43da-abdf-cb01369c3ad1",
      "report_path": "deepseek_v3_2/base/deeplx-app/h3__deepseek-chat__base__deeplx-app__run1_20260104_002739_857874e9.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:27:40.248746+00:00",
      "repo_url": "https://github.com/xixu-me/DeepLX-App",
      "repo_name": "deeplx-app",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 101.32352685928345,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 21,
      "tokens_used": 318469,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "6c59f158-2b3a-49f8-8464-5e9a3cb1df48",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/deeplx-app-6c59f158-2b3a-49f8-8464-5e9a3cb1df48",
      "report_path": "deepseek_v3_2/best_practices/deeplx-app/h3__deepseek-chat__best_practices__deeplx-app__run1_20260104_002933_70792ed7.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:29:33.406068+00:00",
      "repo_url": "https://github.com/rafuwu/mtg-scryfall-randomizer",
      "repo_name": "mtg-scryfall-randomizer",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 12.37357211112976,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 7,
      "tokens_used": 34414,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "bef6e8ed-aa79-4752-96ee-90306c7db36e",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/mtg-scryfall-randomizer-bef6e8ed-aa79-4752-96ee-90306c7db36e",
      "report_path": "google_gemini_2-5_flash/base/mtg-scryfall-randomizer/h3__gemini-2-5-flash__base__mtg-scryfall-randomizer__run1_20260104_002955_5b1473b6.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:29:55.571025+00:00",
      "repo_url": "https://github.com/rafuwu/mtg-scryfall-randomizer",
      "repo_name": "mtg-scryfall-randomizer",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 12.539867162704468,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 28251,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "ba1bc066-e1a7-488b-92a0-a9515237fe74",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/mtg-scryfall-randomizer-ba1bc066-e1a7-488b-92a0-a9515237fe74",
      "report_path": "google_gemini_2-5_flash/best_practices/mtg-scryfall-randomizer/h3__gemini-2-5-flash__best_practices__mtg-scryfall-randomizer__run1_20260104_003037_d57401ce.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:30:37.949102+00:00",
      "repo_url": "https://github.com/rafuwu/mtg-scryfall-randomizer",
      "repo_name": "mtg-scryfall-randomizer",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 42.17630910873413,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 9,
      "tokens_used": 33448,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "e2892b9a-0ab1-4c69-9684-de2626d90a76",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/mtg-scryfall-randomizer-e2892b9a-0ab1-4c69-9684-de2626d90a76",
      "report_path": "openai_gpt5_mini/base/mtg-scryfall-randomizer/h3__gpt-5-mini__base__mtg-scryfall-randomizer__run1_20260104_003129_cafc0ecf.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:31:30.381970+00:00",
      "repo_url": "https://github.com/rafuwu/mtg-scryfall-randomizer",
      "repo_name": "mtg-scryfall-randomizer",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 100.2934021949768,
      "overall_score": 73.66666666666666,
      "dockerfile_score": 100.0,
      "k8s_score": 96.66666666666666,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 13,
      "tokens_used": 70610,
      "error_count": 0,
      "warning_count": 1,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "d03bb04e-3d04-4f0e-9e7e-59f05e0a69ae",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/mtg-scryfall-randomizer-d03bb04e-3d04-4f0e-9e7e-59f05e0a69ae",
      "report_path": "openai_gpt5_mini/best_practices/mtg-scryfall-randomizer/h3__gpt-5-mini__best_practices__mtg-scryfall-randomizer__run1_20260104_003321_84944ed2.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:33:21.739870+00:00",
      "repo_url": "https://github.com/rafuwu/mtg-scryfall-randomizer",
      "repo_name": "mtg-scryfall-randomizer",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 95.7414698600769,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 18,
      "tokens_used": 155376,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "b198bcd6-db70-4266-9724-0283274f6084",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/mtg-scryfall-randomizer-b198bcd6-db70-4266-9724-0283274f6084",
      "report_path": "deepseek_v3_2/base/mtg-scryfall-randomizer/h3__deepseek-chat__base__mtg-scryfall-randomizer__run1_20260104_003507_a239e1e4.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:35:07.945331+00:00",
      "repo_url": "https://github.com/rafuwu/mtg-scryfall-randomizer",
      "repo_name": "mtg-scryfall-randomizer",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 98.96081304550171,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 20,
      "tokens_used": 188368,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "19bfc817-421b-4be8-a36c-2683d4e8b1e3",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/mtg-scryfall-randomizer-19bfc817-421b-4be8-a36c-2683d4e8b1e3",
      "report_path": "deepseek_v3_2/best_practices/mtg-scryfall-randomizer/h3__deepseek-chat__best_practices__mtg-scryfall-randomizer__run1_20260104_003658_36186dd2.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:36:58.458563+00:00",
      "repo_url": "https://github.com/hsalvesen/vesen",
      "repo_name": "vesen",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 15.689754962921143,
      "overall_score": 70.93333333333332,
      "dockerfile_score": 96.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 7,
      "tokens_used": 35220,
      "error_count": 0,
      "warning_count": 3,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "582e7ac3-3abd-48e7-90e1-a4f54efbb0f0",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/vesen-582e7ac3-3abd-48e7-90e1-a4f54efbb0f0",
      "report_path": "google_gemini_2-5_flash/base/vesen/h3__gemini-2-5-flash__base__vesen__run1_20260104_003730_1c7b1bc3.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:37:30.874922+00:00",
      "repo_url": "https://github.com/hsalvesen/vesen",
      "repo_name": "vesen",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 18.87684988975525,
      "overall_score": 29.749999999999996,
      "dockerfile_score": 85.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 8,
      "tokens_used": 47226,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": false,
      "k8s_syntax_valid": null,
      "run_id": "a6419330-1d28-428c-b0fe-32e1024b0ee1",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/vesen-a6419330-1d28-428c-b0fe-32e1024b0ee1",
      "report_path": "google_gemini_2-5_flash/best_practices/vesen/h3__gemini-2-5-flash__best_practices__vesen__run1_20260104_003757_d98ffcdb.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:37:57.838498+00:00",
      "repo_url": "https://github.com/hsalvesen/vesen",
      "repo_name": "vesen",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 68.00299382209778,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 18,
      "tokens_used": 112045,
      "error_count": 1,
      "warning_count": 1,
      "info_count": 1,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "b14c9c90-ed84-451f-a535-4f77a40b4d03",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/vesen-b14c9c90-ed84-451f-a535-4f77a40b4d03",
      "report_path": "openai_gpt5_mini/base/vesen/h3__gpt-5-mini__base__vesen__run1_20260104_003916_5d62d03b.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:39:16.718820+00:00",
      "repo_url": "https://github.com/hsalvesen/vesen",
      "repo_name": "vesen",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 106.48846912384033,
      "overall_score": 73.66666666666666,
      "dockerfile_score": 100.0,
      "k8s_score": 96.66666666666666,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 12,
      "tokens_used": 101662,
      "error_count": 0,
      "warning_count": 1,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "d8f79a17-6851-402f-a2d3-e9a65bee2c0c",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/vesen-d8f79a17-6851-402f-a2d3-e9a65bee2c0c",
      "report_path": "openai_gpt5_mini/best_practices/vesen/h3__gpt-5-mini__best_practices__vesen__run1_20260104_004128_24251688.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:41:28.767738+00:00",
      "repo_url": "https://github.com/hsalvesen/vesen",
      "repo_name": "vesen",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 94.19862604141235,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 16,
      "tokens_used": 101867,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "ab52a584-3c49-4b84-a039-b3e9a9ed334a",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/vesen-ab52a584-3c49-4b84-a039-b3e9a9ed334a",
      "report_path": "deepseek_v3_2/base/vesen/h3__deepseek-chat__base__vesen__run1_20260104_004314_cb385ff8.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:43:15.227934+00:00",
      "repo_url": "https://github.com/hsalvesen/vesen",
      "repo_name": "vesen",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 154.64025902748108,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 28,
      "tokens_used": 215030,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 1,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "64d0fef4-aaa5-4bda-acd0-e9ca013686c4",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/vesen-64d0fef4-aaa5-4bda-acd0-e9ca013686c4",
      "report_path": "deepseek_v3_2/best_practices/vesen/h3__deepseek-chat__best_practices__vesen__run1_20260104_004600_3bf85643.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:46:01.071140+00:00",
      "repo_url": "https://github.com/AdaptChat/webclient.git",
      "repo_name": "webclient",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 15.862524271011353,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 8,
      "tokens_used": 66192,
      "error_count": 1,
      "warning_count": 1,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "9e761004-3a2a-4996-800c-a5d4991799df",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/webclient-9e761004-3a2a-4996-800c-a5d4991799df",
      "report_path": "google_gemini_2-5_flash/base/webclient/h3__gemini-2-5-flash__base__webclient__run1_20260104_004625_982ed83d.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:46:25.933034+00:00",
      "repo_url": "https://github.com/AdaptChat/webclient.git",
      "repo_name": "webclient",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 21.19589591026306,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 11,
      "tokens_used": 65808,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "0143df6c-0c27-48df-a402-e1a34d34bf6f",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/webclient-0143df6c-0c27-48df-a402-e1a34d34bf6f",
      "report_path": "google_gemini_2-5_flash/best_practices/webclient/h3__gemini-2-5-flash__best_practices__webclient__run1_20260104_004908_827aef79.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:49:09.170374+00:00",
      "repo_url": "https://github.com/AdaptChat/webclient.git",
      "repo_name": "webclient",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 95.21030712127686,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 16,
      "tokens_used": 156782,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "8566709f-8c6c-4f40-85d2-d8b4c1694349",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/webclient-8566709f-8c6c-4f40-85d2-d8b4c1694349",
      "report_path": "openai_gpt5_mini/base/webclient/h3__gpt-5-mini__base__webclient__run1_20260104_005318_d675f4c3.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:53:20.672349+00:00",
      "repo_url": "https://github.com/AdaptChat/webclient.git",
      "repo_name": "webclient",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 106.17324995994568,
      "overall_score": 72.96666666666667,
      "dockerfile_score": 98.0,
      "k8s_score": 96.66666666666666,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 19,
      "tokens_used": 169586,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "e5cbb319-1dcf-4667-abac-b2d91b52e298",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/webclient-e5cbb319-1dcf-4667-abac-b2d91b52e298",
      "report_path": "openai_gpt5_mini/best_practices/webclient/h3__gpt-5-mini__best_practices__webclient__run1_20260104_005632_4257ef05.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:56:32.998498+00:00",
      "repo_url": "https://github.com/AdaptChat/webclient.git",
      "repo_name": "webclient",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 163.39137411117554,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 21,
      "tokens_used": 912508,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "2508d99e-9b18-4ddb-b42d-12103c07664f",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/webclient-2508d99e-9b18-4ddb-b42d-12103c07664f",
      "report_path": "deepseek_v3_2/base/webclient/h3__deepseek-chat__base__webclient__run1_20260104_005927_84eaf5b1.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-03T23:59:28.249326+00:00",
      "repo_url": "https://github.com/AdaptChat/webclient.git",
      "repo_name": "webclient",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 207.69191098213196,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 27,
      "tokens_used": 1272441,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "cae78d32-a1dc-4007-82e5-852e6eeab288",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/webclient-cae78d32-a1dc-4007-82e5-852e6eeab288",
      "report_path": "deepseek_v3_2/best_practices/webclient/h3__deepseek-chat__best_practices__webclient__run1_20260104_010305_f927da1b.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:03:06.157302+00:00",
      "repo_url": "https://github.com/prathmesh-ka-github/Chessable",
      "repo_name": "chessable",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 27.339624881744385,
      "overall_score": 69.0,
      "dockerfile_score": 100.0,
      "k8s_score": 85.0,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 14,
      "tokens_used": 95357,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": false,
      "run_id": "de0e1b6c-a4e4-481c-a1dd-7ac7873763bc",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/chessable-de0e1b6c-a4e4-481c-a1dd-7ac7873763bc",
      "report_path": "google_gemini_2-5_flash/base/chessable/h3__gemini-2-5-flash__base__chessable__run1_20260104_010347_8b596beb.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:03:47.450525+00:00",
      "repo_url": "https://github.com/prathmesh-ka-github/Chessable",
      "repo_name": "chessable",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 28.053631067276,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 11,
      "tokens_used": 168354,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "a7932d43-b5ad-4a50-a8db-17b9aa77cd1b",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/chessable-a7932d43-b5ad-4a50-a8db-17b9aa77cd1b",
      "report_path": "google_gemini_2-5_flash/best_practices/chessable/h3__gemini-2-5-flash__best_practices__chessable__run1_20260104_010448_3f4d5fd3.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:04:48.614266+00:00",
      "repo_url": "https://github.com/prathmesh-ka-github/Chessable",
      "repo_name": "chessable",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "failed",
      "generation_success": false,
      "generation_time": 70.09771013259888,
      "overall_score": 0,
      "dockerfile_score": null,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 0,
      "tokens_used": null,
      "error_count": null,
      "warning_count": null,
      "info_count": null,
      "has_errors": null,
      "is_clean": null,
      "dockerfile_syntax_valid": null,
      "k8s_syntax_valid": null,
      "run_id": null,
      "workspace_dir": null,
      "report_path": "openai_gpt5_mini/base/chessable/h3__gpt-5-mini__base__chessable__run1_20260104_010558_d773486d.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:05:59.116366+00:00",
      "repo_url": "https://github.com/prathmesh-ka-github/Chessable",
      "repo_name": "chessable",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 114.35137391090393,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 20,
      "tokens_used": 162058,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "9622618c-fb05-4018-ba46-392c7dba2430",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/chessable-9622618c-fb05-4018-ba46-392c7dba2430",
      "report_path": "openai_gpt5_mini/best_practices/chessable/h3__gpt-5-mini__best_practices__chessable__run1_20260104_010811_c8073813.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:08:12.438393+00:00",
      "repo_url": "https://github.com/prathmesh-ka-github/Chessable",
      "repo_name": "chessable",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 180.09744000434875,
      "overall_score": 69.0,
      "dockerfile_score": 100.0,
      "k8s_score": 85.0,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 32,
      "tokens_used": 292486,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": false,
      "run_id": "603f5e67-c84e-4dc0-b1d6-4e1691be1160",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/chessable-603f5e67-c84e-4dc0-b1d6-4e1691be1160",
      "report_path": "deepseek_v3_2/base/chessable/h3__deepseek-chat__base__chessable__run1_20260104_011126_516b9d55.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:11:27.243637+00:00",
      "repo_url": "https://github.com/prathmesh-ka-github/Chessable",
      "repo_name": "chessable",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 167.48321104049683,
      "overall_score": 73.66666666666666,
      "dockerfile_score": 100.0,
      "k8s_score": 96.66666666666666,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 29,
      "tokens_used": 573604,
      "error_count": 0,
      "warning_count": 1,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "88f50564-924e-4c6f-9df5-452e448e5421",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/chessable-88f50564-924e-4c6f-9df5-452e448e5421",
      "report_path": "deepseek_v3_2/best_practices/chessable/h3__deepseek-chat__best_practices__chessable__run1_20260104_011431_193de3d4.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:14:32.525678+00:00",
      "repo_url": "https://github.com/MindlessTruffle/Class-Order-Checker",
      "repo_name": "class-order-checker",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 9.539232015609741,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 24107,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "4834970d-70f7-4909-bb2d-92a0fd2239a4",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/class-order-checker-4834970d-70f7-4909-bb2d-92a0fd2239a4",
      "report_path": "google_gemini_2-5_flash/base/class-order-checker/h3__gemini-2-5-flash__base__class-order-checker__run1_20260104_011452_82fce209.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:14:52.466345+00:00",
      "repo_url": "https://github.com/MindlessTruffle/Class-Order-Checker",
      "repo_name": "class-order-checker",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 10.691329956054688,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 28854,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "633dc1c7-b069-4944-891b-e253d062132c",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/class-order-checker-633dc1c7-b069-4944-891b-e253d062132c",
      "report_path": "google_gemini_2-5_flash/best_practices/class-order-checker/h3__gemini-2-5-flash__best_practices__class-order-checker__run1_20260104_011514_c1e2e1cf.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:15:14.770492+00:00",
      "repo_url": "https://github.com/MindlessTruffle/Class-Order-Checker",
      "repo_name": "class-order-checker",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 35.17055320739746,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 10,
      "tokens_used": 44591,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "ad95ed6b-aa14-4bfd-8444-7c74dff141c9",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/class-order-checker-ad95ed6b-aa14-4bfd-8444-7c74dff141c9",
      "report_path": "openai_gpt5_mini/base/class-order-checker/h3__gpt-5-mini__base__class-order-checker__run1_20260104_011559_da511e5d.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:15:59.884590+00:00",
      "repo_url": "https://github.com/MindlessTruffle/Class-Order-Checker",
      "repo_name": "class-order-checker",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 73.65288090705872,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 21,
      "tokens_used": 160781,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "213d1e46-ea0d-41aa-8f3e-faafd4289840",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/class-order-checker-213d1e46-ea0d-41aa-8f3e-faafd4289840",
      "report_path": "openai_gpt5_mini/best_practices/class-order-checker/h3__gpt-5-mini__best_practices__class-order-checker__run1_20260104_011724_eb86a0e4.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:17:24.764230+00:00",
      "repo_url": "https://github.com/MindlessTruffle/Class-Order-Checker",
      "repo_name": "class-order-checker",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 89.05368709564209,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 18,
      "tokens_used": 175690,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "62f78b20-2bd9-47cf-bf92-0732ac7d18d5",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/class-order-checker-62f78b20-2bd9-47cf-bf92-0732ac7d18d5",
      "report_path": "deepseek_v3_2/base/class-order-checker/h3__deepseek-chat__base__class-order-checker__run1_20260104_011903_0617f5fe.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:19:03.847949+00:00",
      "repo_url": "https://github.com/MindlessTruffle/Class-Order-Checker",
      "repo_name": "class-order-checker",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 111.48387598991394,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 17,
      "tokens_used": 175966,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "88b77014-31d2-4f22-83a8-ab6e19a1fcf5",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/class-order-checker-88b77014-31d2-4f22-83a8-ab6e19a1fcf5",
      "report_path": "deepseek_v3_2/best_practices/class-order-checker/h3__deepseek-chat__best_practices__class-order-checker__run1_20260104_012107_c93aa1db.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:21:07.602969+00:00",
      "repo_url": "https://github.com/isixe/AdSenseDetective.git",
      "repo_name": "adsensedetective",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 14.558115243911743,
      "overall_score": 70.93333333333332,
      "dockerfile_score": 96.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 7,
      "tokens_used": 25299,
      "error_count": 0,
      "warning_count": 4,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "53d24732-8590-47b8-b7d5-7614dd4fb64d",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/adsensedetective-53d24732-8590-47b8-b7d5-7614dd4fb64d",
      "report_path": "google_gemini_2-5_flash/base/adsensedetective/h3__gemini-2-5-flash__base__adsensedetective__run1_20260104_012218_7b32f40d.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:22:19.313029+00:00",
      "repo_url": "https://github.com/isixe/AdSenseDetective.git",
      "repo_name": "adsensedetective",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 15.350225925445557,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 7,
      "tokens_used": 39167,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "593becf7-d491-4773-8960-c0058985a8da",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/adsensedetective-593becf7-d491-4773-8960-c0058985a8da",
      "report_path": "google_gemini_2-5_flash/best_practices/adsensedetective/h3__gemini-2-5-flash__best_practices__adsensedetective__run1_20260104_012327_f092d4c8.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:23:28.696535+00:00",
      "repo_url": "https://github.com/isixe/AdSenseDetective.git",
      "repo_name": "adsensedetective",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 94.15541386604309,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 24,
      "tokens_used": 191589,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "b2ac6e24-2a70-421e-a8a7-7dd944078f24",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/adsensedetective-b2ac6e24-2a70-421e-a8a7-7dd944078f24",
      "report_path": "openai_gpt5_mini/base/adsensedetective/h3__gpt-5-mini__base__adsensedetective__run1_20260104_012749_02eeb27d.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:27:50.625847+00:00",
      "repo_url": "https://github.com/isixe/AdSenseDetective.git",
      "repo_name": "adsensedetective",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 152.72501301765442,
      "overall_score": 29.749999999999996,
      "dockerfile_score": 85.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 32,
      "tokens_used": 287289,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": false,
      "k8s_syntax_valid": null,
      "run_id": "4ba89f6a-278c-4bcb-82dc-b0f8fb8c2a60",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/adsensedetective-4ba89f6a-278c-4bcb-82dc-b0f8fb8c2a60",
      "report_path": "openai_gpt5_mini/best_practices/adsensedetective/h3__gpt-5-mini__best_practices__adsensedetective__run1_20260104_013032_c1c8db5f.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:30:33.426033+00:00",
      "repo_url": "https://github.com/isixe/AdSenseDetective.git",
      "repo_name": "adsensedetective",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 150.31821012496948,
      "overall_score": 55.599999999999994,
      "dockerfile_score": 96.0,
      "k8s_score": 55.0,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 28,
      "tokens_used": 454712,
      "error_count": 3,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": false,
      "run_id": "d1d1a8fc-599b-4f50-85da-80713845bbb2",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/adsensedetective-d1d1a8fc-599b-4f50-85da-80713845bbb2",
      "report_path": "deepseek_v3_2/base/adsensedetective/h3__deepseek-chat__base__adsensedetective__run1_20260104_013413_4b64b2bd.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:34:14.306265+00:00",
      "repo_url": "https://github.com/isixe/AdSenseDetective.git",
      "repo_name": "adsensedetective",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 340.7073612213135,
      "overall_score": 57.0,
      "dockerfile_score": 100.0,
      "k8s_score": 55.0,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 48,
      "tokens_used": 1029800,
      "error_count": 3,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": false,
      "run_id": "4da47901-3a22-4821-8608-166446089793",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/adsensedetective-4da47901-3a22-4821-8608-166446089793",
      "report_path": "deepseek_v3_2/best_practices/adsensedetective/h3__deepseek-chat__best_practices__adsensedetective__run1_20260104_014105_f82e5a73.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:41:06.011448+00:00",
      "repo_url": "https://github.com/robweber/mario-kart-tournament",
      "repo_name": "mario-kart-tournament",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 24.210755109786987,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 13,
      "tokens_used": 156819,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "82b9021b-8911-4a6c-9f7f-a8c25ab8981d",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/mario-kart-tournament-82b9021b-8911-4a6c-9f7f-a8c25ab8981d",
      "report_path": "google_gemini_2-5_flash/base/mario-kart-tournament/h3__gemini-2-5-flash__base__mario-kart-tournament__run1_20260104_014145_1e72bbd4.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:41:46.123376+00:00",
      "repo_url": "https://github.com/robweber/mario-kart-tournament",
      "repo_name": "mario-kart-tournament",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 30.202069997787476,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 11,
      "tokens_used": 82555,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "be9d796d-bfff-43f2-94c9-6ba5dc889b88",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/mario-kart-tournament-be9d796d-bfff-43f2-94c9-6ba5dc889b88",
      "report_path": "google_gemini_2-5_flash/best_practices/mario-kart-tournament/h3__gemini-2-5-flash__best_practices__mario-kart-tournament__run1_20260104_014230_d9a49d74.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:42:30.656681+00:00",
      "repo_url": "https://github.com/robweber/mario-kart-tournament",
      "repo_name": "mario-kart-tournament",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 107.98351907730103,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 34,
      "tokens_used": 443927,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "07d28640-6699-4eca-bea9-bbe000b2e104",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/mario-kart-tournament-07d28640-6699-4eca-bea9-bbe000b2e104",
      "report_path": "openai_gpt5_mini/base/mario-kart-tournament/h3__gpt-5-mini__base__mario-kart-tournament__run1_20260104_014433_e8ad51d1.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:44:34.015482+00:00",
      "repo_url": "https://github.com/robweber/mario-kart-tournament",
      "repo_name": "mario-kart-tournament",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 439.3857629299164,
      "overall_score": 68.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 83.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 51,
      "tokens_used": 3121555,
      "error_count": 0,
      "warning_count": 5,
      "info_count": 1,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "0d49faed-781f-480b-912b-2f4a5cfc9f89",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/mario-kart-tournament-0d49faed-781f-480b-912b-2f4a5cfc9f89",
      "report_path": "openai_gpt5_mini/best_practices/mario-kart-tournament/h3__gpt-5-mini__best_practices__mario-kart-tournament__run1_20260104_015213_c96c6a91.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:52:13.595348+00:00",
      "repo_url": "https://github.com/robweber/mario-kart-tournament",
      "repo_name": "mario-kart-tournament",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "failed",
      "generation_success": false,
      "generation_time": 41.52648401260376,
      "overall_score": 0,
      "dockerfile_score": null,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 0,
      "tokens_used": null,
      "error_count": null,
      "warning_count": null,
      "info_count": null,
      "has_errors": null,
      "is_clean": null,
      "dockerfile_syntax_valid": null,
      "k8s_syntax_valid": null,
      "run_id": null,
      "workspace_dir": null,
      "report_path": "deepseek_v3_2/base/mario-kart-tournament/h3__deepseek-chat__base__mario-kart-tournament__run1_20260104_015255_a28fdaa9.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:52:55.623801+00:00",
      "repo_url": "https://github.com/robweber/mario-kart-tournament",
      "repo_name": "mario-kart-tournament",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "failed",
      "generation_success": false,
      "generation_time": 278.8837320804596,
      "overall_score": 0,
      "dockerfile_score": null,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 0,
      "tokens_used": null,
      "error_count": null,
      "warning_count": null,
      "info_count": null,
      "has_errors": null,
      "is_clean": null,
      "dockerfile_syntax_valid": null,
      "k8s_syntax_valid": null,
      "run_id": null,
      "workspace_dir": null,
      "report_path": "deepseek_v3_2/best_practices/mario-kart-tournament/h3__deepseek-chat__best_practices__mario-kart-tournament__run1_20260104_015734_5a5db212.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:57:34.942454+00:00",
      "repo_url": "https://github.com/york9675/Tempo-Sync",
      "repo_name": "tempo-sync",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 11.582075119018555,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 25447,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "971532d4-05f5-4aca-8675-e0155b70eddc",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/tempo-sync-971532d4-05f5-4aca-8675-e0155b70eddc",
      "report_path": "google_gemini_2-5_flash/base/tempo-sync/h3__gemini-2-5-flash__base__tempo-sync__run1_20260104_015756_467c7146.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:57:57.044441+00:00",
      "repo_url": "https://github.com/york9675/Tempo-Sync",
      "repo_name": "tempo-sync",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 12.749507904052734,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 29993,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "205e0a84-3221-4e29-bbe9-f9fb820bdd0b",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/tempo-sync-205e0a84-3221-4e29-bbe9-f9fb820bdd0b",
      "report_path": "google_gemini_2-5_flash/best_practices/tempo-sync/h3__gemini-2-5-flash__best_practices__tempo-sync__run1_20260104_015819_39e9cb68.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:58:19.788737+00:00",
      "repo_url": "https://github.com/york9675/Tempo-Sync",
      "repo_name": "tempo-sync",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 37.27042818069458,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 12,
      "tokens_used": 46273,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "6a82b93d-80a5-4d6a-82d0-4108d60272d1",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/tempo-sync-6a82b93d-80a5-4d6a-82d0-4108d60272d1",
      "report_path": "openai_gpt5_mini/base/tempo-sync/h3__gpt-5-mini__base__tempo-sync__run1_20260104_015906_12e65b5f.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T00:59:07.375382+00:00",
      "repo_url": "https://github.com/york9675/Tempo-Sync",
      "repo_name": "tempo-sync",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 65.57833695411682,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 14,
      "tokens_used": 76320,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "6f0f97c9-78ae-4b0f-93eb-14d60a8456ab",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/tempo-sync-6f0f97c9-78ae-4b0f-93eb-14d60a8456ab",
      "report_path": "openai_gpt5_mini/best_practices/tempo-sync/h3__gpt-5-mini__best_practices__tempo-sync__run1_20260104_020023_e9fee88d.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:00:24.212472+00:00",
      "repo_url": "https://github.com/york9675/Tempo-Sync",
      "repo_name": "tempo-sync",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 140.80847001075745,
      "overall_score": 73.66666666666666,
      "dockerfile_score": 100.0,
      "k8s_score": 96.66666666666666,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 18,
      "tokens_used": 856301,
      "error_count": 0,
      "warning_count": 1,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "f8207eda-2c9a-4051-ad50-f68e04e0d614",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/tempo-sync-f8207eda-2c9a-4051-ad50-f68e04e0d614",
      "report_path": "deepseek_v3_2/base/tempo-sync/h3__deepseek-chat__base__tempo-sync__run1_20260104_020257_849fa44c.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:02:58.392755+00:00",
      "repo_url": "https://github.com/york9675/Tempo-Sync",
      "repo_name": "tempo-sync",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 172.24533104896545,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 29,
      "tokens_used": 1062581,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "4657b8a1-81be-4997-907f-85647fc58acf",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/tempo-sync-4657b8a1-81be-4997-907f-85647fc58acf",
      "report_path": "deepseek_v3_2/best_practices/tempo-sync/h3__deepseek-chat__best_practices__tempo-sync__run1_20260104_020602_3bf57a83.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:06:02.881579+00:00",
      "repo_url": "https://github.com/bhavish00007/Attendence-Calculator",
      "repo_name": "attendence-calculator",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 10.040287971496582,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 23347,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "0a6f578b-856a-4c3f-a516-5b1374cc6334",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/attendence-calculator-0a6f578b-856a-4c3f-a516-5b1374cc6334",
      "report_path": "google_gemini_2-5_flash/base/attendence-calculator/h3__gemini-2-5-flash__base__attendence-calculator__run1_20260104_020621_2f9c9bf4.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:06:22.401253+00:00",
      "repo_url": "https://github.com/bhavish00007/Attendence-Calculator",
      "repo_name": "attendence-calculator",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 10.249054193496704,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 27831,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "643556d3-7b4d-4ab8-bc5e-427963517320",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/attendence-calculator-643556d3-7b4d-4ab8-bc5e-427963517320",
      "report_path": "google_gemini_2-5_flash/best_practices/attendence-calculator/h3__gemini-2-5-flash__best_practices__attendence-calculator__run1_20260104_020642_c84ee6a1.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:06:42.653189+00:00",
      "repo_url": "https://github.com/bhavish00007/Attendence-Calculator",
      "repo_name": "attendence-calculator",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 59.14851403236389,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 18,
      "tokens_used": 82857,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "68f4fd92-fddc-46a6-a135-869f80a21ae0",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/attendence-calculator-68f4fd92-fddc-46a6-a135-869f80a21ae0",
      "report_path": "openai_gpt5_mini/base/attendence-calculator/h3__gpt-5-mini__base__attendence-calculator__run1_20260104_020752_cc5ff476.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:07:53.330443+00:00",
      "repo_url": "https://github.com/bhavish00007/Attendence-Calculator",
      "repo_name": "attendence-calculator",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "failed",
      "generation_success": false,
      "generation_time": 72.81110620498657,
      "overall_score": 0,
      "dockerfile_score": null,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 0,
      "tokens_used": null,
      "error_count": null,
      "warning_count": null,
      "info_count": null,
      "has_errors": null,
      "is_clean": null,
      "dockerfile_syntax_valid": null,
      "k8s_syntax_valid": null,
      "run_id": null,
      "workspace_dir": null,
      "report_path": "openai_gpt5_mini/best_practices/attendence-calculator/h3__gpt-5-mini__best_practices__attendence-calculator__run1_20260104_020906_28aa587e.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:09:06.583896+00:00",
      "repo_url": "https://github.com/bhavish00007/Attendence-Calculator",
      "repo_name": "attendence-calculator",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 112.9567940235138,
      "overall_score": 73.66666666666666,
      "dockerfile_score": 100.0,
      "k8s_score": 96.66666666666666,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 19,
      "tokens_used": 118700,
      "error_count": 0,
      "warning_count": 1,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "c0881c80-b32f-49ff-a2e2-0fa45f9a4be4",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/attendence-calculator-c0881c80-b32f-49ff-a2e2-0fa45f9a4be4",
      "report_path": "deepseek_v3_2/base/attendence-calculator/h3__deepseek-chat__base__attendence-calculator__run1_20260104_021109_1db48511.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:11:10.322471+00:00",
      "repo_url": "https://github.com/bhavish00007/Attendence-Calculator",
      "repo_name": "attendence-calculator",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 118.95368599891663,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 19,
      "tokens_used": 130830,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "4dcc06bb-baaa-4a1f-a06f-5bf75a47fa7e",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/attendence-calculator-4dcc06bb-baaa-4a1f-a06f-5bf75a47fa7e",
      "report_path": "deepseek_v3_2/best_practices/attendence-calculator/h3__deepseek-chat__best_practices__attendence-calculator__run1_20260104_021320_11326675.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:13:20.562373+00:00",
      "repo_url": "https://github.com/9582anupam/scheme-seva.git",
      "repo_name": "scheme-seva",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 46.86899709701538,
      "overall_score": 65.6,
      "dockerfile_score": 96.0,
      "k8s_score": 79.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 24,
      "tokens_used": 230825,
      "error_count": 0,
      "warning_count": 7,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "91784517-fbe0-44b5-94d3-9e9704e7f8ef",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/scheme-seva-91784517-fbe0-44b5-94d3-9e9704e7f8ef",
      "report_path": "google_gemini_2-5_flash/base/scheme-seva/h3__gemini-2-5-flash__base__scheme-seva__run1_20260104_021527_0449ba51.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:15:29.055905+00:00",
      "repo_url": "https://github.com/9582anupam/scheme-seva.git",
      "repo_name": "scheme-seva",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 55.65587902069092,
      "overall_score": 29.749999999999996,
      "dockerfile_score": 85.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 30,
      "tokens_used": 149694,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": false,
      "k8s_syntax_valid": null,
      "run_id": "9dcae053-1de9-44d6-817f-6712a7774f5f",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/scheme-seva-9dcae053-1de9-44d6-817f-6712a7774f5f",
      "report_path": "google_gemini_2-5_flash/best_practices/scheme-seva/h3__gemini-2-5-flash__best_practices__scheme-seva__run1_20260104_021635_5f30e4f5.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:16:35.716899+00:00",
      "repo_url": "https://github.com/9582anupam/scheme-seva.git",
      "repo_name": "scheme-seva",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 177.65086317062378,
      "overall_score": 67.0,
      "dockerfile_score": 100.0,
      "k8s_score": 79.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 33,
      "tokens_used": 285839,
      "error_count": 0,
      "warning_count": 6,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "1259e5f3-afc8-40c2-9a76-a91a2b49dba9",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/scheme-seva-1259e5f3-afc8-40c2-9a76-a91a2b49dba9",
      "report_path": "openai_gpt5_mini/base/scheme-seva/h3__gpt-5-mini__base__scheme-seva__run1_20260104_022100_4c813f0b.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:21:02.225319+00:00",
      "repo_url": "https://github.com/9582anupam/scheme-seva.git",
      "repo_name": "scheme-seva",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 411.24516320228577,
      "overall_score": 69.6,
      "dockerfile_score": 96.0,
      "k8s_score": 89.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 48,
      "tokens_used": 2189213,
      "error_count": 0,
      "warning_count": 4,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "6134228f-35ea-49fe-9aa0-60d7b2c5a4a9",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/scheme-seva-6134228f-35ea-49fe-9aa0-60d7b2c5a4a9",
      "report_path": "openai_gpt5_mini/best_practices/scheme-seva/h3__gpt-5-mini__best_practices__scheme-seva__run1_20260104_022920_5a1fe523.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:29:22.067151+00:00",
      "repo_url": "https://github.com/9582anupam/scheme-seva.git",
      "repo_name": "scheme-seva",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 479.97217297554016,
      "overall_score": 67.6,
      "dockerfile_score": 96.0,
      "k8s_score": 85.0,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 63,
      "tokens_used": 889705,
      "error_count": 1,
      "warning_count": 1,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": false,
      "run_id": "4c1acd69-b4b7-44de-868d-2b8fcf181600",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/scheme-seva-4c1acd69-b4b7-44de-868d-2b8fcf181600",
      "report_path": "deepseek_v3_2/base/scheme-seva/h3__deepseek-chat__base__scheme-seva__run1_20260104_023845_05548dd4.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:38:46.804439+00:00",
      "repo_url": "https://github.com/9582anupam/scheme-seva.git",
      "repo_name": "scheme-seva",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 428.46533823013306,
      "overall_score": 73.66666666666666,
      "dockerfile_score": 100.0,
      "k8s_score": 96.66666666666666,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 57,
      "tokens_used": 1046038,
      "error_count": 0,
      "warning_count": 1,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "0968b8c7-eac4-4e34-aacb-c7bc00a2bd27",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/scheme-seva-0968b8c7-eac4-4e34-aacb-c7bc00a2bd27",
      "report_path": "deepseek_v3_2/best_practices/scheme-seva/h3__deepseek-chat__best_practices__scheme-seva__run1_20260104_024724_148ffb53.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:47:25.176371+00:00",
      "repo_url": "https://github.com/efsavage/hello-world-war",
      "repo_name": "hello-world-war",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 15.512239933013916,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 7,
      "tokens_used": 28331,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "4d1b2b25-4602-47f7-aa99-5592eec6c790",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/hello-world-war-4d1b2b25-4602-47f7-aa99-5592eec6c790",
      "report_path": "google_gemini_2-5_flash/base/hello-world-war/h3__gemini-2-5-flash__base__hello-world-war__run1_20260104_024758_a358361a.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:47:59.331170+00:00",
      "repo_url": "https://github.com/efsavage/hello-world-war",
      "repo_name": "hello-world-war",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 15.211714029312134,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 21202,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "a21684d6-1baa-438d-9a68-a7c4c0c96e97",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/hello-world-war-a21684d6-1baa-438d-9a68-a7c4c0c96e97",
      "report_path": "google_gemini_2-5_flash/best_practices/hello-world-war/h3__gemini-2-5-flash__best_practices__hello-world-war__run1_20260104_024829_2794295d.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:48:30.131799+00:00",
      "repo_url": "https://github.com/efsavage/hello-world-war",
      "repo_name": "hello-world-war",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 40.73878192901611,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 19,
      "tokens_used": 73787,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "fd406de2-8764-4e33-8f59-27873b07cd45",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/hello-world-war-fd406de2-8764-4e33-8f59-27873b07cd45",
      "report_path": "openai_gpt5_mini/base/hello-world-war/h3__gpt-5-mini__base__hello-world-war__run1_20260104_024920_c17958be.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:49:21.106875+00:00",
      "repo_url": "https://github.com/efsavage/hello-world-war",
      "repo_name": "hello-world-war",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 78.1853518486023,
      "overall_score": 29.749999999999996,
      "dockerfile_score": 85.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 20,
      "tokens_used": 102920,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": false,
      "k8s_syntax_valid": null,
      "run_id": "2d14cdfa-56d3-406f-9847-8ab79dcbcc9f",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/hello-world-war-2d14cdfa-56d3-406f-9847-8ab79dcbcc9f",
      "report_path": "openai_gpt5_mini/best_practices/hello-world-war/h3__gpt-5-mini__best_practices__hello-world-war__run1_20260104_025047_6754252f.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:50:48.164067+00:00",
      "repo_url": "https://github.com/efsavage/hello-world-war",
      "repo_name": "hello-world-war",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 144.147047996521,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 23,
      "tokens_used": 126756,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "a691c2d3-29bc-4bb6-94c6-e09b4941e14b",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/hello-world-war-a691c2d3-29bc-4bb6-94c6-e09b4941e14b",
      "report_path": "deepseek_v3_2/base/hello-world-war/h3__deepseek-chat__base__hello-world-war__run1_20260104_025327_d8376ad0.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:53:27.825113+00:00",
      "repo_url": "https://github.com/efsavage/hello-world-war",
      "repo_name": "hello-world-war",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 139.48153972625732,
      "overall_score": 29.749999999999996,
      "dockerfile_score": 85.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 26,
      "tokens_used": 153936,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": false,
      "k8s_syntax_valid": null,
      "run_id": "850519aa-4f93-439c-a24d-fbdca3ee6c8c",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/hello-world-war-850519aa-4f93-439c-a24d-fbdca3ee6c8c",
      "report_path": "deepseek_v3_2/best_practices/hello-world-war/h3__deepseek-chat__best_practices__hello-world-war__run1_20260104_025555_7e76fd4e.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:55:55.963759+00:00",
      "repo_url": "https://github.com/FullStackWithLawrence/openai-hello-world",
      "repo_name": "openai-hello-world",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 17.392616033554077,
      "overall_score": 70.93333333333332,
      "dockerfile_score": 96.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 10,
      "tokens_used": 31585,
      "error_count": 0,
      "warning_count": 3,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "0279b1a1-3d6f-4ac6-b747-af89f378c98e",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/openai-hello-world-0279b1a1-3d6f-4ac6-b747-af89f378c98e",
      "report_path": "google_gemini_2-5_flash/base/openai-hello-world/h3__gemini-2-5-flash__base__openai-hello-world__run1_20260104_025631_dccf47a2.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:56:31.412468+00:00",
      "repo_url": "https://github.com/FullStackWithLawrence/openai-hello-world",
      "repo_name": "openai-hello-world",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 21.41286301612854,
      "overall_score": 29.749999999999996,
      "dockerfile_score": 85.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 33877,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": false,
      "k8s_syntax_valid": null,
      "run_id": "b0086d6e-54c1-4326-8bc4-347afaf0ca10",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/openai-hello-world-b0086d6e-54c1-4326-8bc4-347afaf0ca10",
      "report_path": "google_gemini_2-5_flash/best_practices/openai-hello-world/h3__gemini-2-5-flash__best_practices__openai-hello-world__run1_20260104_025700_1811b77e.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:57:01.094151+00:00",
      "repo_url": "https://github.com/FullStackWithLawrence/openai-hello-world",
      "repo_name": "openai-hello-world",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 126.88079833984375,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 41,
      "tokens_used": 276959,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "3a45fa5a-738c-42cf-a043-66cd8e26c6a9",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/openai-hello-world-3a45fa5a-738c-42cf-a043-66cd8e26c6a9",
      "report_path": "openai_gpt5_mini/base/openai-hello-world/h3__gpt-5-mini__base__openai-hello-world__run1_20260104_025927_66fe957a.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T01:59:27.636053+00:00",
      "repo_url": "https://github.com/FullStackWithLawrence/openai-hello-world",
      "repo_name": "openai-hello-world",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 101.8636212348938,
      "overall_score": 62.3,
      "dockerfile_score": 98.0,
      "k8s_score": 70.0,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 35,
      "tokens_used": 247601,
      "error_count": 2,
      "warning_count": 1,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": false,
      "run_id": "193fdd8d-e1cf-43b3-8a43-8fe9062454a4",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/openai-hello-world-193fdd8d-e1cf-43b3-8a43-8fe9062454a4",
      "report_path": "openai_gpt5_mini/best_practices/openai-hello-world/h3__gpt-5-mini__best_practices__openai-hello-world__run1_20260104_030148_eb18ed49.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T02:01:48.981684+00:00",
      "repo_url": "https://github.com/FullStackWithLawrence/openai-hello-world",
      "repo_name": "openai-hello-world",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 226.0651137828827,
      "overall_score": 72.26666666666665,
      "dockerfile_score": 96.0,
      "k8s_score": 96.66666666666666,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 34,
      "tokens_used": 388851,
      "error_count": 0,
      "warning_count": 3,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "747213ca-1278-4475-b5b0-5fcea7de7210",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/openai-hello-world-747213ca-1278-4475-b5b0-5fcea7de7210",
      "report_path": "deepseek_v3_2/base/openai-hello-world/h3__deepseek-chat__base__openai-hello-world__run1_20260104_030608_3f151e7d.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T02:06:09.532900+00:00",
      "repo_url": "https://github.com/FullStackWithLawrence/openai-hello-world",
      "repo_name": "openai-hello-world",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 381.0781297683716,
      "overall_score": 43.599999999999994,
      "dockerfile_score": 96.0,
      "k8s_score": 25.0,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 48,
      "tokens_used": 684598,
      "error_count": 5,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": false,
      "run_id": "e3ce6e2a-2ffc-46a6-9a67-4bbd38468af8",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/openai-hello-world-e3ce6e2a-2ffc-46a6-9a67-4bbd38468af8",
      "report_path": "deepseek_v3_2/best_practices/openai-hello-world/h3__deepseek-chat__best_practices__openai-hello-world__run1_20260104_031315_9228c01f.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T02:13:15.394068+00:00",
      "repo_url": "https://github.com/angelvicenteg/ToDo-List",
      "repo_name": "todo-list",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 14.001067161560059,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 23252,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "df45b4c8-cadb-4515-99a3-0d73637b0b3b",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/todo-list-df45b4c8-cadb-4515-99a3-0d73637b0b3b",
      "report_path": "google_gemini_2-5_flash/base/todo-list/h3__gemini-2-5-flash__base__todo-list__run1_20260104_031339_dbef2544.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T02:13:39.723253+00:00",
      "repo_url": "https://github.com/angelvicenteg/ToDo-List",
      "repo_name": "todo-list",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 13.029160976409912,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 6,
      "tokens_used": 27982,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "e2608aa4-acd2-4a5c-b732-2eba12e84b6a",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/todo-list-e2608aa4-acd2-4a5c-b732-2eba12e84b6a",
      "report_path": "google_gemini_2-5_flash/best_practices/todo-list/h3__gemini-2-5-flash__best_practices__todo-list__run1_20260104_031434_8166b9c4.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T02:14:34.834788+00:00",
      "repo_url": "https://github.com/angelvicenteg/ToDo-List",
      "repo_name": "todo-list",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 234.35678577423096,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 13,
      "tokens_used": 79432,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "4a75289a-5940-421d-9d07-721d7d4410a5",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/todo-list-4a75289a-5940-421d-9d07-721d7d4410a5",
      "report_path": "openai_gpt5_mini/base/todo-list/h3__gpt-5-mini__base__todo-list__run1_20260104_031838_37f38656.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T02:18:39.424583+00:00",
      "repo_url": "https://github.com/angelvicenteg/ToDo-List",
      "repo_name": "todo-list",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 63.47898507118225,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 13,
      "tokens_used": 71895,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "391b3a25-4d65-4f4f-961a-15299e663680",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/todo-list-391b3a25-4d65-4f4f-961a-15299e663680",
      "report_path": "openai_gpt5_mini/best_practices/todo-list/h3__gpt-5-mini__best_practices__todo-list__run1_20260104_031954_1f566488.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T02:19:55.246233+00:00",
      "repo_url": "https://github.com/angelvicenteg/ToDo-List",
      "repo_name": "todo-list",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 90.08197617530823,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 17,
      "tokens_used": 157431,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "1ddef591-abb2-44b6-b1f6-63424d4e7f8f",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/todo-list-1ddef591-abb2-44b6-b1f6-63424d4e7f8f",
      "report_path": "deepseek_v3_2/base/todo-list/h3__deepseek-chat__base__todo-list__run1_20260104_032135_2e7f5218.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T02:21:35.662365+00:00",
      "repo_url": "https://github.com/angelvicenteg/ToDo-List",
      "repo_name": "todo-list",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": false,
      "runtime_success": false,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 112.09958624839783,
      "overall_score": 0.0,
      "dockerfile_score": 0.0,
      "k8s_score": null,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 16,
      "tokens_used": 153698,
      "error_count": 1,
      "warning_count": 0,
      "info_count": 1,
      "has_errors": true,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": null,
      "run_id": "f285c4f4-a0d6-4f82-9960-d84b38bf81d6",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/todo-list-f285c4f4-a0d6-4f82-9960-d84b38bf81d6",
      "report_path": "deepseek_v3_2/best_practices/todo-list/h3__deepseek-chat__best_practices__todo-list__run1_20260104_032337_d0a46af3.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T02:23:38.286696+00:00",
      "repo_url": "https://github.com/mmumshad/simple-webapp-flask",
      "repo_name": "simple-webapp-flask",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 10.33449912071228,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 8,
      "tokens_used": 27218,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "1a5729c3-7598-480f-8a0d-71ab859d8e3c",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/simple-webapp-flask-1a5729c3-7598-480f-8a0d-71ab859d8e3c",
      "report_path": "google_gemini_2-5_flash/base/simple-webapp-flask/h3__gemini-2-5-flash__base__simple-webapp-flask__run1_20260104_032401_c7c9eb44.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T02:24:02.044819+00:00",
      "repo_url": "https://github.com/mmumshad/simple-webapp-flask",
      "repo_name": "simple-webapp-flask",
      "model_provider": "google_genai",
      "model_name": "gemini-2.5-flash",
      "model_label": "google_gemini_2.5_flash",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 20.006587028503418,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 8,
      "tokens_used": 37325,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "38314f2b-668b-4a80-81a0-d3d5fcfae065",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/simple-webapp-flask-38314f2b-668b-4a80-81a0-d3d5fcfae065",
      "report_path": "google_gemini_2-5_flash/best_practices/simple-webapp-flask/h3__gemini-2-5-flash__best_practices__simple-webapp-flask__run1_20260104_032504_3ce95d6c.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T02:25:05.007601+00:00",
      "repo_url": "https://github.com/mmumshad/simple-webapp-flask",
      "repo_name": "simple-webapp-flask",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 48.658374071121216,
      "overall_score": 72.33333333333333,
      "dockerfile_score": 100.0,
      "k8s_score": 93.33333333333331,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 13,
      "tokens_used": 47767,
      "error_count": 0,
      "warning_count": 2,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "4b79ee9d-bbdb-4722-940d-309bc7a7397f",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/simple-webapp-flask-4b79ee9d-bbdb-4722-940d-309bc7a7397f",
      "report_path": "openai_gpt5_mini/base/simple-webapp-flask/h3__gpt-5-mini__base__simple-webapp-flask__run1_20260104_032611_af08b66b.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T02:26:12.227726+00:00",
      "repo_url": "https://github.com/mmumshad/simple-webapp-flask",
      "repo_name": "simple-webapp-flask",
      "model_provider": "openai",
      "model_name": "gpt-5-mini",
      "model_label": "openai_gpt5_mini",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 104.87293291091919,
      "overall_score": 75.0,
      "dockerfile_score": 100.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 23,
      "tokens_used": 117546,
      "error_count": 0,
      "warning_count": 0,
      "info_count": 0,
      "has_errors": false,
      "is_clean": true,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "4e621152-fc0b-4ad2-bdb0-ba256b27063e",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/simple-webapp-flask-4e621152-fc0b-4ad2-bdb0-ba256b27063e",
      "report_path": "openai_gpt5_mini/best_practices/simple-webapp-flask/h3__gpt-5-mini__best_practices__simple-webapp-flask__run1_20260104_032813_8cd4173b.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T02:28:14.510985+00:00",
      "repo_url": "https://github.com/mmumshad/simple-webapp-flask",
      "repo_name": "simple-webapp-flask",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "base",
      "prompt_description": "Base prompt (same as H1)",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/default.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 92.41061496734619,
      "overall_score": 72.26666666666665,
      "dockerfile_score": 96.0,
      "k8s_score": 96.66666666666666,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 16,
      "tokens_used": 75405,
      "error_count": 0,
      "warning_count": 3,
      "info_count": 0,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "d7009177-c119-4774-8b56-bc42546308e6",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/simple-webapp-flask-d7009177-c119-4774-8b56-bc42546308e6",
      "report_path": "deepseek_v3_2/base/simple-webapp-flask/h3__deepseek-chat__base__simple-webapp-flask__run1_20260104_033005_22e380bd.json"
    },
    {
      "experiment": "h3",
      "timestamp": "2026-01-04T02:30:06.023488+00:00",
      "repo_url": "https://github.com/mmumshad/simple-webapp-flask",
      "repo_name": "simple-webapp-flask",
      "model_provider": "deepseek",
      "model_name": "deepseek-chat",
      "model_label": "deepseek_v3_2",
      "temperature": 1.0,
      "seed": null,
      "prompt_id": "best_practices",
      "prompt_description": "Best-practices prompt",
      "prompt_source_path": "/Users/rasztabigab/Studia/run/prompts/best_practices.prompt",
      "build_success": true,
      "runtime_success": null,
      "repetition": 0,
      "status": "completed",
      "generation_success": true,
      "generation_time": 139.40836024284363,
      "overall_score": 74.3,
      "dockerfile_score": 98.0,
      "k8s_score": 99.99999999999999,
      "runtime_score": null,
      "docker_llm_score": null,
      "k8s_llm_score": null,
      "tool_calls": 22,
      "tokens_used": 128698,
      "error_count": 0,
      "warning_count": 1,
      "info_count": 1,
      "has_errors": false,
      "is_clean": false,
      "dockerfile_syntax_valid": true,
      "k8s_syntax_valid": true,
      "run_id": "63d5fb29-5d57-400a-96fb-af1889c61906",
      "workspace_dir": "/Users/rasztabigab/Studia/run/tmp/simple-webapp-flask-63d5fb29-5d57-400a-96fb-af1889c61906",
      "report_path": "deepseek_v3_2/best_practices/simple-webapp-flask/h3__deepseek-chat__best_practices__simple-webapp-flask__run1_20260104_033255_dc6f4624.json"
    }
  ]
}